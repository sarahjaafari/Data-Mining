{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["Sara Aljaafari - 169044425<br>\n", "Assignent 1 - CP421"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Question 1 - 1.a)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import fetch_california_housing\n", "import pandas as pd\n", "#1.b)\n", "housing_dataset=fetch_california_housing()\n", "housing =pd.DataFrame(data=housing_dataset.data, columns=housing_dataset.feature_names)\n", "print(housing.head())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["2.a)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(housing.shape)\n", "print(housing.columns)\n", "print(housing.dtypes)\n", "print(housing.describe())"]}, {"cell_type": "markdown", "metadata": {}, "source": [".b)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "housing.hist(bins=50, figsize=(20, 15))\n", "#plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["3.a)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "missing=np.random.choice(housing.index,size=int(len(housing)*0.1),replace=False)\n", "housing.loc[missing, 'AveRooms']=np.nan\n", "housing.loc[missing, 'AveOccup']=np.nan"]}, {"cell_type": "markdown", "metadata": {}, "source": ["3.b)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["housing['AveRooms'].fillna(housing['AveRooms'].mean(), inplace=True)\n", "housing['AveOccup'].fillna(housing['AveOccup'].mean(), inplace=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["4.a b)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import StandardScaler\n", "target=housing_dataset.target\n", "housing_features = housing.copy()\n", "scaler=StandardScaler()\n", "housing_scaled=pd.DataFrame(scaler.fit_transform(housing_features), columns=housing_features.columns)\n", "housing_scaled['target'] =target\n", "print(housing_scaled.head())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["QUESTON 2<br>\n", "1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "X=housing_scaled.drop('target',axis=1)\n", "y=housing_scaled['target']\n", "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=42)"]}, {"cell_type": "markdown", "metadata": {}, "source": [".a)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LinearRegression, Lasso, Ridge\n", "# Linear regression\n", "linear_model=LinearRegression()\n", "linear_model.fit(X_train, y_train)\n", "lasso_model =Lasso(alpha=0.1, random_state=42)\n", "lasso_model.fit(X_train, y_train)\n", "ridge_model=Ridge(alpha=1, random_state=42)\n", "ridge_model.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": [".b)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import GridSearchCV\n", "alphas= {'alpha': [0.01, 0.1, 1, 10]}\n", "lasso_grid=GridSearchCV(Lasso(),alphas, cv=5,scoring='neg_mean_squared_error')\n", "lasso_grid.fit(X_train, y_train)\n", "ridge_grid=GridSearchCV(Ridge(),alphas, cv=5,scoring='neg_mean_squared_error')\n", "ridge_grid.fit(X_train, y_train)\n", "lasso_best_est=lasso_grid.best_estimator_\n", "ridge_best_est=ridge_grid.best_estimator_\n", "print(lasso_grid.best_params_)\n", "print(ridge_grid.best_params_)"]}, {"cell_type": "markdown", "metadata": {}, "source": [")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n", "linear_pred=linear_model.predict(X_test)\n", "lasso_pred=lasso_best_est.predict(X_test)\n", "ridge_pred=ridge_best_est.predict(X_test)\n", "def evaluate_model(name, y_true, y_pred):\n", "    mse=mean_squared_error(y_true, y_pred)\n", "    mae=mean_absolute_error(y_true, y_pred)\n", "    r2= r2_score(y_true, y_pred)\n", "    print({name})\n", "    print(f\"MSE:{mse}\")\n", "    print(f\"MAE:{mae}\")\n", "    print(f\"R^2:{r2}\")\n", "    print()\n", "#evaluations\n", "evaluate_model(\"Linear Regression\",y_test,linear_pred)\n", "evaluate_model(\"Lasso\",y_test,lasso_pred)\n", "evaluate_model(\"Ridge\",y_test, ridge_pred)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["QUESTION 3<br>\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["medianval =housing_scaled.target.median()\n", "binary_target = (housing_scaled.target>medianval).astype(int)\n", "housing_scaled['binary_target']=binary_target\n", "print(housing_scaled.head())"]}, {"cell_type": "markdown", "metadata": {}, "source": [""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LogisticRegression\n", "X = housing_scaled.drop(['target','binary_target'], axis=1)\n", "y = housing_scaled['binary_target']\n", "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.2, random_state=42)\n", "logistic_model= LogisticRegression(random_state=42)\n", "logistic_model.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": [")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve\n", "#import seaborn as sns\n", "y_pred = logistic_model.predict(X_test)\n", "y_pred_prob = logistic_model.predict_proba(X_test)[:,1]\n", "#evaluations\n", "accuracy=accuracy_score(y_test,y_pred)\n", "precision=precision_score(y_test,y_pred)\n", "recall=recall_score(y_test,y_pred)\n", "f1=f1_score(y_test,y_pred)\n", "roc_auc=roc_auc_score(y_test,y_pred_prob)\n", "# confusion matric\n", "conf_matrix = confusion_matrix(y_test,y_pred)\n", "print(conf_matrix)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["UESTION 4<br>\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.cluster import KMeans\n", "from sklearn.decomposition import PCA\n", "kmcluster = housing_scaled.drop(['target','binary_target'],axis=1) \n", "ssd=[]\n", "kk=range(1,11)\n", "for k in kk:\n", "    kmeans=KMeans(n_clusters=k,random_state=42)\n", "    kmeans.fit(kmcluster)\n", "    ssd.append(kmeans.inertia_)\n", "plt.figure(figsize=(10,5))\n", "plt.plot(kk,ssd,marker='o') \n", "#plt.show()\n", "# ELbow point=3 (it's where I realized the rate of decrease in SSD slows significantly)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["c0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["elbow=3\n", "kmeans=KMeans(n_clusters=elbow, random_state=42)\n", "kmeans.fit(kmcluster)\n", "labels=kmeans.labels_\n", "pca= PCA(n_components=2)\n", "pca2=pca.fit_transform(kmcluster)\n", "plt.figure(figsize=(10,5))\n", "plt.scatter(pca2[:,0],pca2[:,1],c=labels,cmap='viridis',marker='o')\n", "plt.xlabel('PCA1')\n", "plt.ylabel('PCA2')\n", "#plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": [")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.mixture import GaussianMixture\n", "guassmix=GaussianMixture(n_components=2, random_state=42)\n", "guassmix_fit= guassmix.fit_predict(kmcluster)\n", "plt.figure(figsize=(10,5))\n", "plt.scatter(pca2[:,0],pca2[:,1],c=guassmix_fit,cmap='viridis',marker='o')\n", "plt.xlabel('PCA1')\n", "plt.ylabel('PCA2')\n", "#plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": [")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import silhouette_score\n", "kmeans_silhouette = silhouette_score(kmcluster, labels)\n", "guassmix_silhouette = silhouette_score(kmcluster, guassmix_fit)\n", "print(f\"KMeans Silhouette Score: {kmeans_silhouette}\")\n", "print(f\"Gaussian Mixture Silhouette Score: {guassmix_silhouette}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["K means is easy to implement and efficient and better for large datasets. But its weaknes<br>\n", "is that the number of cluster need to be specified in advance, despite that it is more<br>\n", "fficient to test elbow method to find the best number of clusters.<br>\n", "Guassian mixture is more felxible with clustering as it can model clusters with different<br>\n", "sizes. But it is more complex to implement and understand than K means."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}